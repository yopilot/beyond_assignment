2025-07-14 03:00:27,181 - INFO - [loading] 0% - Loading language model...
2025-07-14 03:00:27,182 - INFO - Using CPU for inference.
2025-07-14 03:00:27,182 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium...
2025-07-14 03:01:52,544 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:01:52,932 - WARNING - Failed to load microsoft/DialoGPT-medium: You cannot use both `pipeline(... torch_dtype=..., model_kwargs={"torch_dtype":...})` as those arguments might conflict, use only one.)
2025-07-14 03:01:52,933 - INFO - [loading] 30% - Failed to load microsoft/DialoGPT-medium, trying next...
2025-07-14 03:01:52,933 - INFO - [loading] 20% - Trying gpt2...
2025-07-14 03:01:59,957 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:02:00,463 - WARNING - Failed to load gpt2: You cannot use both `pipeline(... torch_dtype=..., model_kwargs={"torch_dtype":...})` as those arguments might conflict, use only one.)
2025-07-14 03:02:00,464 - INFO - [loading] 30% - Failed to load gpt2, trying next...
2025-07-14 03:02:00,464 - INFO - [loading] 20% - Trying distilgpt2...
2025-07-14 03:02:07,203 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:02:07,498 - WARNING - Failed to load distilgpt2: You cannot use both `pipeline(... torch_dtype=..., model_kwargs={"torch_dtype":...})` as those arguments might conflict, use only one.)
2025-07-14 03:02:07,498 - INFO - [loading] 30% - Failed to load distilgpt2, trying next...
2025-07-14 03:02:35,872 - INFO - [loading] 0% - Loading language model...
2025-07-14 03:02:35,872 - INFO - Using CPU for inference.
2025-07-14 03:02:35,872 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium...
2025-07-14 03:03:57,010 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:03:59,186 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-07-14 03:07:10,465 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully!
2025-07-14 03:07:10,467 - INFO - Successfully loaded microsoft/DialoGPT-medium
2025-07-14 03:41:12,792 - INFO - === SYSTEM INFORMATION ===
2025-07-14 03:41:12,793 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 03:41:13,948 - INFO - CUDA available: True
2025-07-14 03:41:13,948 - INFO - CUDA version: 11.8
2025-07-14 03:41:13,949 - INFO - Number of GPUs: 1
2025-07-14 03:41:13,951 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 03:41:13,951 - INFO - ===========================
2025-07-14 03:52:54,450 - INFO - === SYSTEM INFORMATION ===
2025-07-14 03:52:54,451 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 03:52:54,451 - INFO - CUDA available: True
2025-07-14 03:52:54,451 - INFO - CUDA version: 11.8
2025-07-14 03:52:54,451 - INFO - Number of GPUs: 1
2025-07-14 03:52:54,452 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 03:52:54,452 - INFO - ===========================
2025-07-14 03:53:57,324 - INFO - === SYSTEM INFORMATION ===
2025-07-14 03:53:57,325 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 03:53:57,325 - INFO - CUDA available: True
2025-07-14 03:53:57,325 - INFO - CUDA version: 11.8
2025-07-14 03:53:57,325 - INFO - Number of GPUs: 1
2025-07-14 03:53:57,325 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 03:53:57,325 - INFO - ===========================
2025-07-14 03:54:51,521 - INFO - === SYSTEM INFORMATION ===
2025-07-14 03:54:51,522 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 03:54:51,523 - INFO - CUDA available: True
2025-07-14 03:54:51,523 - INFO - CUDA version: 11.8
2025-07-14 03:54:51,523 - INFO - Number of GPUs: 1
2025-07-14 03:54:51,523 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 03:54:51,523 - INFO - ===========================
2025-07-14 03:54:51,524 - INFO - [loading] 0% - Loading language model...
2025-07-14 03:54:51,525 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:51] "POST /generate HTTP/1.1" 200 -
2025-07-14 03:54:51,525 - INFO - [loading] 0% - Loading language model...
2025-07-14 03:54:51,526 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 03:54:51,526 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 03:54:51,526 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 03:54:52,542 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:52] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:54:52,913 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:54:52,913 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:54:53,236 - WARNING - Failed to load microsoft/DialoGPT-medium on cuda:0: You cannot use both `pipeline(... torch_dtype=..., model_kwargs={"torch_dtype":...})` as those arguments might conflict, use only one.)
2025-07-14 03:54:53,236 - INFO - [loading] 30% - Failed to load microsoft/DialoGPT-medium, trying next...
2025-07-14 03:54:53,237 - INFO - [loading] 30% - Failed to load microsoft/DialoGPT-medium, trying next...
2025-07-14 03:54:53,237 - INFO - [loading] 20% - Trying gpt2 on cuda:0...
2025-07-14 03:54:53,237 - INFO - [loading] 20% - Trying gpt2 on cuda:0...
2025-07-14 03:54:53,545 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:53] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:54:54,267 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:54:54,268 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:54:54,540 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:54] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:54:54,559 - WARNING - Failed to load gpt2 on cuda:0: You cannot use both `pipeline(... torch_dtype=..., model_kwargs={"torch_dtype":...})` as those arguments might conflict, use only one.)
2025-07-14 03:54:54,559 - INFO - [loading] 30% - Failed to load gpt2, trying next...
2025-07-14 03:54:54,559 - INFO - [loading] 30% - Failed to load gpt2, trying next...
2025-07-14 03:54:54,560 - INFO - [loading] 20% - Trying distilgpt2 on cuda:0...
2025-07-14 03:54:54,560 - INFO - [loading] 20% - Trying distilgpt2 on cuda:0...
2025-07-14 03:54:55,538 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:55] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:54:56,226 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:54:56,226 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:54:56,531 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:56] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:54:57,023 - WARNING - Failed to load distilgpt2 on cuda:0: You cannot use both `pipeline(... torch_dtype=..., model_kwargs={"torch_dtype":...})` as those arguments might conflict, use only one.)
2025-07-14 03:54:57,023 - INFO - [loading] 30% - Failed to load distilgpt2, trying next...
2025-07-14 03:54:57,024 - INFO - [loading] 30% - Failed to load distilgpt2, trying next...
2025-07-14 03:54:57,024 - ERROR - Error in persona generation pipeline: No suitable model could be loaded. Please check your internet connection and try again.
2025-07-14 03:54:57,024 - ERROR - Generation failed: No suitable model could be loaded. Please check your internet connection and try again.
2025-07-14 03:54:57,532 - INFO - 127.0.0.1 - - [14/Jul/2025 03:54:57] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:56:09,852 - INFO -  * Detected change in 'C:\\Users\\Yaxh\\Desktop\\TRY\\model_manager.py', reloading
2025-07-14 03:57:10,702 - INFO - === SYSTEM INFORMATION ===
2025-07-14 03:57:10,703 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 03:57:10,703 - INFO - CUDA available: True
2025-07-14 03:57:10,703 - INFO - CUDA version: 11.8
2025-07-14 03:57:10,704 - INFO - Number of GPUs: 1
2025-07-14 03:57:10,704 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 03:57:10,704 - INFO - ===========================
2025-07-14 03:57:10,705 - INFO - [loading] 0% - Loading language model...
2025-07-14 03:57:10,705 - INFO - 127.0.0.1 - - [14/Jul/2025 03:57:10] "POST /generate HTTP/1.1" 200 -
2025-07-14 03:57:10,706 - INFO - [loading] 0% - Loading language model...
2025-07-14 03:57:10,706 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 03:57:10,706 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 03:57:10,707 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 03:57:11,579 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:57:11,579 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:57:11,722 - INFO - 127.0.0.1 - - [14/Jul/2025 03:57:11] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:57:12,719 - INFO - 127.0.0.1 - - [14/Jul/2025 03:57:12] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:57:12,842 - WARNING - Failed to load microsoft/DialoGPT-medium on cuda:0: Could not load model microsoft/DialoGPT-medium with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>). See the original errors:

while loading with AutoModelForCausalLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 292, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 310, in infer_framework_load_model
    model = model_class.from_pretrained(model, **fp32_kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

while loading with GPT2LMHeadModel, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 292, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 310, in infer_framework_load_model
    model = model_class.from_pretrained(model, **fp32_kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`



2025-07-14 03:57:12,843 - INFO - [loading] 30% - Failed to load microsoft/DialoGPT-medium, trying next...
2025-07-14 03:57:12,843 - INFO - [loading] 30% - Failed to load microsoft/DialoGPT-medium, trying next...
2025-07-14 03:57:12,844 - INFO - [loading] 20% - Trying gpt2 on cuda:0...
2025-07-14 03:57:12,844 - INFO - [loading] 20% - Trying gpt2 on cuda:0...
2025-07-14 03:57:13,722 - INFO - 127.0.0.1 - - [14/Jul/2025 03:57:13] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:57:14,021 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:57:14,022 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:57:14,327 - WARNING - Failed to load gpt2 on cuda:0: Could not load model gpt2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>). See the original errors:

while loading with AutoModelForCausalLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 292, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 310, in infer_framework_load_model
    model = model_class.from_pretrained(model, **fp32_kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

while loading with GPT2LMHeadModel, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 292, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 310, in infer_framework_load_model
    model = model_class.from_pretrained(model, **fp32_kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`



2025-07-14 03:57:14,328 - INFO - [loading] 30% - Failed to load gpt2, trying next...
2025-07-14 03:57:14,329 - INFO - [loading] 30% - Failed to load gpt2, trying next...
2025-07-14 03:57:14,329 - INFO - [loading] 20% - Trying distilgpt2 on cuda:0...
2025-07-14 03:57:14,329 - INFO - [loading] 20% - Trying distilgpt2 on cuda:0...
2025-07-14 03:57:14,719 - INFO - 127.0.0.1 - - [14/Jul/2025 03:57:14] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:57:15,360 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:57:15,360 - INFO - [loading] 60% - Loading model weights...
2025-07-14 03:57:15,649 - WARNING - Failed to load distilgpt2 on cuda:0: Could not load model distilgpt2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>). See the original errors:

while loading with AutoModelForCausalLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 292, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 310, in infer_framework_load_model
    model = model_class.from_pretrained(model, **fp32_kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\models\auto\auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

while loading with GPT2LMHeadModel, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 292, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\pipelines\base.py", line 310, in infer_framework_load_model
    model = model_class.from_pretrained(model, **fp32_kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 311, in _wrapper
    return func(*args, **kwargs)
  File "C:\Users\Yaxh\miniconda3\Lib\site-packages\transformers\modeling_utils.py", line 4546, in from_pretrained
    raise ValueError(
    ...<2 lines>...
    )
ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`



2025-07-14 03:57:15,650 - INFO - [loading] 30% - Failed to load distilgpt2, trying next...
2025-07-14 03:57:15,650 - INFO - [loading] 30% - Failed to load distilgpt2, trying next...
2025-07-14 03:57:15,651 - ERROR - Error in persona generation pipeline: No suitable model could be loaded. Please check your internet connection and try again.
2025-07-14 03:57:15,651 - ERROR - Generation failed: No suitable model could be loaded. Please check your internet connection and try again.
2025-07-14 03:57:15,716 - INFO - 127.0.0.1 - - [14/Jul/2025 03:57:15] "GET /progress HTTP/1.1" 200 -
2025-07-14 03:59:00,390 - INFO -  * Detected change in 'C:\\Users\\Yaxh\\Desktop\\TRY\\model_manager.py', reloading
2025-07-14 04:03:27,047 - INFO - === SYSTEM INFORMATION ===
2025-07-14 04:03:27,048 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 04:03:27,048 - INFO - CUDA available: True
2025-07-14 04:03:27,048 - INFO - CUDA version: 11.8
2025-07-14 04:03:27,049 - INFO - Number of GPUs: 1
2025-07-14 04:03:27,049 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 04:03:27,049 - INFO - ===========================
2025-07-14 04:04:10,448 - INFO - === SYSTEM INFORMATION ===
2025-07-14 04:04:10,449 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 04:04:10,449 - INFO - CUDA available: True
2025-07-14 04:04:10,449 - INFO - CUDA version: 11.8
2025-07-14 04:04:10,449 - INFO - Number of GPUs: 1
2025-07-14 04:04:10,450 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 04:04:10,450 - INFO - ===========================
2025-07-14 04:04:10,451 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:04:10,451 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:10] "POST /generate HTTP/1.1" 200 -
2025-07-14 04:04:10,451 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:04:10,452 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 04:04:10,452 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:04:10,452 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:04:11,473 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:11] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:12,042 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:04:12,043 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:04:13,356 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:13] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:14,367 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:14] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:15,386 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:15] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:16,470 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:16] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:17,355 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:17] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:17,542 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2025-07-14 04:04:18,351 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:18] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:19,347 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:19] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:20,101 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:04:20,102 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:04:20,102 - INFO - Successfully loaded microsoft/DialoGPT-medium on cuda:0
2025-07-14 04:04:20,103 - INFO - GPU Memory - Allocated: 0.69GB, Reserved: 0.73GB
2025-07-14 04:04:20,103 - INFO - [scraping] 0% - Starting to scrape user: Mysterious_Tax9562
2025-07-14 04:04:20,103 - INFO - [scraping] 0% - Starting to scrape user: Mysterious_Tax9562
2025-07-14 04:04:20,349 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:20] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:21,350 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:21] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:22,352 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:22] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:22,990 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:04:22,990 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:04:23,346 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:23] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:24,352 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:24] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:25,002 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:04:25,002 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:04:25,003 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:04:25,003 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:04:25,003 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:04:25,003 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:04:25,003 - INFO - [scraping] 26% - Processed 40 posts...
2025-07-14 04:04:25,004 - INFO - [scraping] 26% - Processed 40 posts...
2025-07-14 04:04:25,004 - INFO - [scraping] 30% - Processed 50 posts...
2025-07-14 04:04:25,004 - INFO - [scraping] 30% - Processed 50 posts...
2025-07-14 04:04:25,004 - INFO - [scraping] 34% - Processed 60 posts...
2025-07-14 04:04:25,004 - INFO - [scraping] 34% - Processed 60 posts...
2025-07-14 04:04:25,005 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:04:25,005 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:04:25,351 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:25] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:25,875 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:04:25,876 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:04:25,876 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:04:25,876 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:04:25,876 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:04:25,877 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:04:25,877 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:04:25,877 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:04:25,877 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:04:25,877 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:04:26,359 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:26] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:26,729 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:04:26,730 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:04:26,730 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:04:26,730 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:04:26,730 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:04:26,731 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:04:26,735 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:04:26,735 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:04:26,735 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:04:26,736 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:04:26,736 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:04:26,736 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:04:26,736 - INFO - [scraping] 100% - Scraping complete! Found 67 posts and 155 comments
2025-07-14 04:04:26,736 - INFO - [scraping] 100% - Scraping complete! Found 67 posts and 155 comments
2025-07-14 04:04:26,737 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:04:26,737 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:04:26,737 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:04:26,737 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:04:26,737 - INFO - Prompt truncated to prevent hanging
2025-07-14 04:04:26,738 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:04:26,738 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:04:27,352 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:27] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:04:27,764 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:04:27,765 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:04:27,766 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:04:27,766 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:04:27,766 - INFO - [saving] 0% - Saving results...
2025-07-14 04:04:27,766 - INFO - [saving] 0% - Saving results...
2025-07-14 04:04:27,771 - INFO - [saving] 100% - Results saved to output\Mysterious_Tax9562_persona_20250714_040427.txt
2025-07-14 04:04:27,771 - INFO - [saving] 100% - Results saved to output\Mysterious_Tax9562_persona_20250714_040427.txt
2025-07-14 04:04:28,354 - INFO - 127.0.0.1 - - [14/Jul/2025 04:04:28] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:24,786 - INFO - === SYSTEM INFORMATION ===
2025-07-14 04:11:24,786 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 04:11:24,786 - INFO - CUDA available: True
2025-07-14 04:11:24,786 - INFO - CUDA version: 11.8
2025-07-14 04:11:24,786 - INFO - Number of GPUs: 1
2025-07-14 04:11:24,787 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 04:11:24,787 - INFO - ===========================
2025-07-14 04:11:24,788 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:11:24,788 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:24] "POST /generate HTTP/1.1" 200 -
2025-07-14 04:11:24,789 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:11:24,789 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 04:11:24,789 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:11:24,790 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:11:25,849 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:11:25,849 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:11:26,356 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:26] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:27,360 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:27] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:28,365 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:28] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:29,352 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:29] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:30,347 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:30] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:31,346 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:31] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:31,798 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:31] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:31,885 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:11:31,886 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:11:31,886 - INFO - Successfully loaded microsoft/DialoGPT-medium on cuda:0
2025-07-14 04:11:31,887 - INFO - GPU Memory - Allocated: 0.69GB, Reserved: 0.73GB
2025-07-14 04:11:31,887 - INFO - [scraping] 0% - Starting to scrape user: kojied
2025-07-14 04:11:31,887 - INFO - [scraping] 0% - Starting to scrape user: kojied
2025-07-14 04:11:32,801 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:32] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:33,193 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:11:33,194 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:11:34,249 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:11:34,250 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:11:34,250 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:11:34,250 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:11:34,250 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:11:34,250 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:11:34,251 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:11:34,251 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:11:34,359 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:34] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:35,360 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:35] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:35,803 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:35] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:35,963 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:11:35,963 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:11:35,963 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:11:35,963 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:11:35,964 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:11:35,964 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:11:35,964 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:11:35,964 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:11:35,964 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:11:35,964 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:11:37,336 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:11:37,336 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:11:37,336 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:11:37,336 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:11:37,337 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:11:37,337 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:11:37,337 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:11:37,337 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:11:37,337 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:11:37,337 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:11:37,338 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:11:37,338 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:11:37,338 - INFO - [scraping] 100% - Scraping complete! Found 31 posts and 196 comments
2025-07-14 04:11:37,338 - INFO - [scraping] 100% - Scraping complete! Found 31 posts and 196 comments
2025-07-14 04:11:37,338 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:11:37,338 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:11:37,339 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:11:37,339 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:11:37,339 - INFO - Prompt truncated to prevent hanging
2025-07-14 04:11:37,339 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:11:37,339 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:11:37,353 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:37] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:11:38,257 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:11:38,257 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:11:38,259 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:11:38,259 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:11:38,259 - INFO - [saving] 0% - Saving results...
2025-07-14 04:11:38,259 - INFO - [saving] 0% - Saving results...
2025-07-14 04:11:38,265 - INFO - [saving] 100% - Results saved to output\kojied_persona_20250714_041138.txt
2025-07-14 04:11:38,266 - INFO - [saving] 100% - Results saved to output\kojied_persona_20250714_041138.txt
2025-07-14 04:11:38,356 - INFO - 127.0.0.1 - - [14/Jul/2025 04:11:38] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:40,427 - INFO - === SYSTEM INFORMATION ===
2025-07-14 04:29:40,427 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 04:29:40,427 - INFO - CUDA available: True
2025-07-14 04:29:40,428 - INFO - CUDA version: 11.8
2025-07-14 04:29:40,428 - INFO - Number of GPUs: 1
2025-07-14 04:29:40,428 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 04:29:40,428 - INFO - ===========================
2025-07-14 04:29:40,429 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:29:40,430 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:40] "POST /generate HTTP/1.1" 200 -
2025-07-14 04:29:40,430 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:29:40,430 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 04:29:40,431 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:29:40,431 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:29:41,451 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:41] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:41,812 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:29:41,812 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:29:43,369 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:43] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:44,370 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:44] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:45,573 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:45] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:46,347 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:46] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:47,359 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:47] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:48,359 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:48] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:49,185 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:49] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:49,420 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:29:49,421 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:29:49,421 - INFO - Successfully loaded microsoft/DialoGPT-medium on cuda:0
2025-07-14 04:29:49,422 - INFO - GPU Memory - Allocated: 0.69GB, Reserved: 0.73GB
2025-07-14 04:29:49,422 - INFO - [scraping] 0% - Starting to scrape user: kojied
2025-07-14 04:29:49,423 - INFO - [scraping] 0% - Starting to scrape user: kojied
2025-07-14 04:29:49,446 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:49] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:50,442 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:50] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:50,631 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:29:50,632 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:29:51,439 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:51] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:51,679 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:29:51,679 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:29:51,679 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:29:51,679 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:29:51,680 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:29:51,680 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:29:51,680 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:29:51,680 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:29:52,439 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:52] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:53,546 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:29:53,546 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:29:53,547 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:29:53,547 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:29:53,547 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:29:53,547 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:29:53,548 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:29:53,548 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:29:53,548 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:29:53,548 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:29:54,353 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:54] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:54,990 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:29:54,990 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:29:54,990 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:29:54,990 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:29:54,991 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:29:54,991 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:29:54,991 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:29:54,991 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:29:54,991 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:29:54,992 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:29:54,992 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:29:54,992 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:29:54,992 - INFO - [scraping] 100% - Scraping complete! Found 31 posts and 196 comments
2025-07-14 04:29:54,993 - INFO - [scraping] 100% - Scraping complete! Found 31 posts and 196 comments
2025-07-14 04:29:54,993 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:29:54,993 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:29:54,993 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:29:54,993 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:29:54,994 - INFO - Prompt truncated to prevent hanging
2025-07-14 04:29:54,994 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:29:54,994 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:29:55,355 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:55] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:29:56,034 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:29:56,034 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:29:56,035 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:29:56,035 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:29:56,036 - INFO - [saving] 0% - Saving results...
2025-07-14 04:29:56,036 - INFO - [saving] 0% - Saving results...
2025-07-14 04:29:56,040 - INFO - [saving] 100% - Results saved to output\kojied_persona_20250714_042956.txt
2025-07-14 04:29:56,040 - INFO - [saving] 100% - Results saved to output\kojied_persona_20250714_042956.txt
2025-07-14 04:29:56,354 - INFO - 127.0.0.1 - - [14/Jul/2025 04:29:56] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:13,431 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "GET / HTTP/1.1" 200 -
2025-07-14 04:30:13,573 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "GET /static/css/components.css HTTP/1.1" 200 -
2025-07-14 04:30:13,579 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "[36mGET /static/css/progress.css HTTP/1.1[0m" 304 -
2025-07-14 04:30:13,583 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2025-07-14 04:30:13,584 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2025-07-14 04:30:13,585 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "GET /static/js/api.js HTTP/1.1" 200 -
2025-07-14 04:30:13,589 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:13] "GET /static/js/utils.js HTTP/1.1" 200 -
2025-07-14 04:30:34,468 - INFO - === SYSTEM INFORMATION ===
2025-07-14 04:30:34,468 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 04:30:34,468 - INFO - CUDA available: True
2025-07-14 04:30:34,469 - INFO - CUDA version: 11.8
2025-07-14 04:30:34,469 - INFO - Number of GPUs: 1
2025-07-14 04:30:34,469 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 04:30:34,470 - INFO - ===========================
2025-07-14 04:30:34,470 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:30:34,471 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:34] "POST /generate HTTP/1.1" 200 -
2025-07-14 04:30:34,471 - INFO - [loading] 0% - Loading language model...
2025-07-14 04:30:34,472 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 04:30:34,472 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:30:34,472 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 04:30:35,290 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:30:35,291 - INFO - [loading] 60% - Loading model weights...
2025-07-14 04:30:36,448 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:36] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:37,443 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:37] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:38,348 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:38] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:38,649 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:30:38,649 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 04:30:38,650 - INFO - Successfully loaded microsoft/DialoGPT-medium on cuda:0
2025-07-14 04:30:38,650 - INFO - GPU Memory - Allocated: 1.38GB, Reserved: 1.44GB
2025-07-14 04:30:38,650 - INFO - [scraping] 0% - Starting to scrape user: kojied
2025-07-14 04:30:38,650 - INFO - [scraping] 0% - Starting to scrape user: kojied
2025-07-14 04:30:39,347 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:39] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:39,654 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:30:39,655 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 04:30:40,346 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:40] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:40,627 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:30:40,627 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 04:30:40,628 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:30:40,628 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 04:30:40,628 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:30:40,628 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 04:30:40,628 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:30:40,629 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 04:30:41,358 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:41] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:42,167 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:30:42,167 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 04:30:42,168 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:30:42,168 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 04:30:42,168 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:30:42,168 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 04:30:42,168 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:30:42,169 - INFO - [scraping] 66% - Processed 80 comments...
2025-07-14 04:30:42,169 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:30:42,169 - INFO - [scraping] 70% - Processed 100 comments...
2025-07-14 04:30:42,352 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:42] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:43,352 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:43] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:43,821 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:30:43,821 - INFO - [scraping] 74% - Processed 120 comments...
2025-07-14 04:30:43,822 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:30:43,822 - INFO - [scraping] 78% - Processed 140 comments...
2025-07-14 04:30:43,822 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:30:43,822 - INFO - [scraping] 82% - Processed 160 comments...
2025-07-14 04:30:43,822 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:30:43,822 - INFO - [scraping] 86% - Processed 180 comments...
2025-07-14 04:30:43,823 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:30:43,823 - INFO - [scraping] 90% - Processed 200 comments...
2025-07-14 04:30:43,823 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:30:43,823 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 04:30:43,824 - INFO - [scraping] 100% - Scraping complete! Found 31 posts and 196 comments
2025-07-14 04:30:43,824 - INFO - [scraping] 100% - Scraping complete! Found 31 posts and 196 comments
2025-07-14 04:30:43,824 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:30:43,824 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 04:30:43,824 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:30:43,825 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 04:30:43,825 - INFO - Prompt truncated to prevent hanging
2025-07-14 04:30:43,825 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:30:43,825 - INFO - [generating] 40% - Generating persona...
2025-07-14 04:30:44,354 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:44] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:44,666 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:30:44,666 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 04:30:44,667 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:30:44,667 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 04:30:44,667 - INFO - [saving] 0% - Saving results...
2025-07-14 04:30:44,667 - INFO - [saving] 0% - Saving results...
2025-07-14 04:30:44,683 - INFO - [saving] 100% - Results saved to output\kojied_persona_20250714_043044.txt
2025-07-14 04:30:44,683 - INFO - [saving] 100% - Results saved to output\kojied_persona_20250714_043044.txt
2025-07-14 04:30:45,350 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:45] "GET /progress HTTP/1.1" 200 -
2025-07-14 04:30:45,357 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:45] "[33mGET /persona_content/output/kojied_persona_20250714_043044.txt HTTP/1.1[0m" 404 -
2025-07-14 04:30:52,368 - INFO - 127.0.0.1 - - [14/Jul/2025 04:30:52] "[33mGET /download/output/kojied_persona_20250714_043044.txt HTTP/1.1[0m" 404 -
2025-07-14 04:31:39,116 - INFO -  * Detected change in 'C:\\Users\\Yaxh\\Desktop\\TRY\\web_interface.py', reloading
2025-07-14 05:06:13,917 - INFO - === SYSTEM INFORMATION ===
2025-07-14 05:06:13,917 - INFO - PyTorch version: 2.7.1+cu118
2025-07-14 05:06:15,166 - INFO - CUDA available: True
2025-07-14 05:06:15,166 - INFO - CUDA version: 11.8
2025-07-14 05:06:15,167 - INFO - Number of GPUs: 1
2025-07-14 05:06:15,174 - INFO - GPU 0: NVIDIA GeForce GTX 1650 (4.0GB)
2025-07-14 05:06:15,174 - INFO - ===========================
2025-07-14 05:06:15,174 - INFO - Using output directory: C:\Users\Yaxh\Desktop\TRY\output
2025-07-14 05:06:15,174 - INFO - [loading] 0% - Loading language model...
2025-07-14 05:06:15,174 - INFO - [loading] 0% - Loading language model...
2025-07-14 05:06:15,174 - INFO - GPU detected! Using CUDA device: NVIDIA GeForce GTX 1650
2025-07-14 05:06:15,174 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 05:06:15,175 - INFO - [loading] 20% - Trying microsoft/DialoGPT-medium on cuda:0...
2025-07-14 05:06:17,410 - INFO - [loading] 60% - Loading model weights...
2025-07-14 05:06:17,411 - INFO - [loading] 60% - Loading model weights...
2025-07-14 05:06:24,508 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 05:06:24,508 - INFO - [loading] 100% - Model microsoft/DialoGPT-medium loaded successfully on cuda:0!
2025-07-14 05:06:24,509 - INFO - Successfully loaded microsoft/DialoGPT-medium on cuda:0
2025-07-14 05:06:24,509 - INFO - GPU Memory - Allocated: 0.69GB, Reserved: 0.73GB
2025-07-14 05:06:24,510 - INFO - [scraping] 0% - Starting to scrape user: AlexAndWhiteRabbit
2025-07-14 05:06:24,510 - INFO - [scraping] 0% - Starting to scrape user: AlexAndWhiteRabbit
2025-07-14 05:06:25,639 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 05:06:25,639 - INFO - [scraping] 10% - Fetching posts...
2025-07-14 05:06:27,541 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 05:06:27,541 - INFO - [scraping] 14% - Processed 10 posts...
2025-07-14 05:06:27,541 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 05:06:27,542 - INFO - [scraping] 18% - Processed 20 posts...
2025-07-14 05:06:27,542 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 05:06:27,542 - INFO - [scraping] 22% - Processed 30 posts...
2025-07-14 05:06:27,542 - INFO - [scraping] 26% - Processed 40 posts...
2025-07-14 05:06:27,542 - INFO - [scraping] 26% - Processed 40 posts...
2025-07-14 05:06:27,542 - INFO - [scraping] 30% - Processed 50 posts...
2025-07-14 05:06:27,543 - INFO - [scraping] 30% - Processed 50 posts...
2025-07-14 05:06:27,543 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 05:06:27,543 - INFO - [scraping] 50% - Fetching comments...
2025-07-14 05:06:28,262 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 05:06:28,262 - INFO - [scraping] 54% - Processed 20 comments...
2025-07-14 05:06:28,262 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 05:06:28,263 - INFO - [scraping] 58% - Processed 40 comments...
2025-07-14 05:06:28,263 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 05:06:28,263 - INFO - [scraping] 62% - Processed 60 comments...
2025-07-14 05:06:28,263 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 05:06:28,263 - INFO - [scraping] 90% - Finalizing scraped data...
2025-07-14 05:06:28,264 - INFO - [scraping] 100% - Scraping complete! Found 55 posts and 47 comments
2025-07-14 05:06:28,264 - INFO - [scraping] 100% - Scraping complete! Found 55 posts and 47 comments
2025-07-14 05:06:28,264 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 05:06:28,264 - INFO - [generating] 0% - Preparing data for persona generation...
2025-07-14 05:06:28,264 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 05:06:28,265 - INFO - [generating] 20% - Creating persona prompt...
2025-07-14 05:06:28,265 - INFO - Prompt truncated to prevent hanging
2025-07-14 05:06:28,265 - INFO - [generating] 40% - Generating persona...
2025-07-14 05:06:28,265 - INFO - [generating] 40% - Generating persona...
2025-07-14 05:06:29,232 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 05:06:29,232 - INFO - [generating] 60% - Using fallback generation method...
2025-07-14 05:06:29,235 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 05:06:29,235 - INFO - [generating] 100% - Persona generation complete (fallback method)!
2025-07-14 05:06:29,235 - INFO - [saving] 0% - Saving results...
2025-07-14 05:06:29,235 - INFO - [saving] 0% - Saving results...
2025-07-14 05:06:29,238 - INFO - [saving] 100% - Results saved to C:\Users\Yaxh\Desktop\TRY\output\AlexAndWhiteRabbit_persona_20250714_050629.txt
2025-07-14 05:06:29,239 - INFO - [saving] 100% - Results saved to C:\Users\Yaxh\Desktop\TRY\output\AlexAndWhiteRabbit_persona_20250714_050629.txt
